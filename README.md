# SVM with Cross Validation

## Overview

This project demonstrates the implementation of a Support Vector Machine
(SVM) model with k-Fold Cross-Validation for performance evaluation. The
notebook explores the use of SVM for classification tasks, highlighting
how cross-validation helps in obtaining a more reliable estimate of
model accuracy.

## Dataset

A generic dataset for classification is used (can be replaced with any
suitable dataset such as Iris or a custom dataset). The dataset is
preprocessed, scaled, and split into training and testing sets before
applying SVM.

## Methodology

-   Data preprocessing (scaling and splitting)
-   Model training using Support Vector Machine (SVM)
-   k-Fold Cross-Validation to validate model performance
-   Performance metrics such as accuracy, precision, recall, and
    F1-score

## Results

The notebook presents model evaluation results including confusion
matrix and classification report. Visualization of results and accuracy
across folds are provided.

## Requirements

Install the following Python libraries before running the notebook:

``` bash
pip install numpy pandas scikit-learn matplotlib
```

## How to Run

1.  Open the Jupyter Notebook file `SVM_with_Cross_Validation.ipynb`.
2.  Run all cells sequentially to execute data loading, training, and
    evaluation.
3.  Review the outputs and performance metrics displayed.

## Author

**Sujay Roy**\
Machine Learning Enthusiast \| Data Science Practitioner

------------------------------------------------------------------------

*This project serves as a demonstration of applying SVM with
cross-validation for robust model evaluation.*
